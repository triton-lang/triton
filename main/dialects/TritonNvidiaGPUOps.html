<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>TritonNvidiaGPUOps &mdash; Triton  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/documentation_options.js?v=5929fcd5"></script>
        <script src="../_static/doctools.js?v=9a2dae69"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="NVGPUOps" href="NVGPUOps.html" />
    <link rel="prev" title="TritonOps" href="TritonOps.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Triton
              <img src="https://cdn.openai.com/triton/assets/triton-logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../getting-started/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting-started/tutorials/index.html">Tutorials</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../python-api/triton.html">triton</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python-api/triton.language.html">triton.language</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python-api/triton.testing.html">triton.testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python-api/triton-semantics.html">Triton Semantics</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Triton MLIR Dialects</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="dialects.html">Triton MLIR Dialects and Ops</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="TritonNvidiaGPUDialect.html">‘triton_nvidia_gpu’ Dialect</a></li>
<li class="toctree-l2"><a class="reference internal" href="TritonGPUDialect.html">‘triton_gpu’ Dialect</a></li>
<li class="toctree-l2"><a class="reference internal" href="NVGPUDialect.html">‘nvgpu’ Dialect</a></li>
<li class="toctree-l2"><a class="reference internal" href="TritonDialect.html">‘tt’ Dialect</a></li>
<li class="toctree-l2"><a class="reference internal" href="TritonGPUOps.html">TritonGPUOps<!-- Autogenerated by mlir-tblgen; don't manually edit --></a></li>
<li class="toctree-l2"><a class="reference internal" href="TritonOps.html">TritonOps<!-- Autogenerated by mlir-tblgen; don't manually edit --></a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">TritonNvidiaGPUOps<!-- Autogenerated by mlir-tblgen; don't manually edit --></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#triton-nvidia-gpu-async-tma-copy-global-to-local-triton-nvidia-gpu-asynctmacopyglobaltolocalop"><code class="docutils literal notranslate"><span class="pre">triton_nvidia_gpu.async_tma_copy_global_to_local</span></code> (triton::nvidia_gpu::AsyncTMACopyGlobalToLocalOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#attributes">Attributes:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#operands">Operands:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#triton-nvidia-gpu-async-tma-copy-local-to-global-triton-nvidia-gpu-asynctmacopylocaltoglobalop"><code class="docutils literal notranslate"><span class="pre">triton_nvidia_gpu.async_tma_copy_local_to_global</span></code> (triton::nvidia_gpu::AsyncTMACopyLocalToGlobalOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">Operands:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#triton-nvidia-gpu-barrier-expect-triton-nvidia-gpu-barrierexpectop"><code class="docutils literal notranslate"><span class="pre">triton_nvidia_gpu.barrier_expect</span></code> (triton::nvidia_gpu::BarrierExpectOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id2">Attributes:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id3">Operands:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#triton-nvidia-gpu-cluster-arrive-triton-nvidia-gpu-clusterarriveop"><code class="docutils literal notranslate"><span class="pre">triton_nvidia_gpu.cluster_arrive</span></code> (triton::nvidia_gpu::ClusterArriveOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id4">Attributes:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#triton-nvidia-gpu-cluster-wait-triton-nvidia-gpu-clusterwaitop"><code class="docutils literal notranslate"><span class="pre">triton_nvidia_gpu.cluster_wait</span></code> (triton::nvidia_gpu::ClusterWaitOp)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#triton-nvidia-gpu-fence-async-shared-triton-nvidia-gpu-fenceasyncsharedop"><code class="docutils literal notranslate"><span class="pre">triton_nvidia_gpu.fence_async_shared</span></code> (triton::nvidia_gpu::FenceAsyncSharedOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id5">Attributes:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#triton-nvidia-gpu-init-barrier-triton-nvidia-gpu-initbarrierop"><code class="docutils literal notranslate"><span class="pre">triton_nvidia_gpu.init_barrier</span></code> (triton::nvidia_gpu::InitBarrierOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id6">Attributes:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id7">Operands:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#triton-nvidia-gpu-inval-barrier-triton-nvidia-gpu-invalbarrierop"><code class="docutils literal notranslate"><span class="pre">triton_nvidia_gpu.inval_barrier</span></code> (triton::nvidia_gpu::InvalBarrierOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id8">Operands:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#triton-nvidia-gpu-async-tma-store-wait-triton-nvidia-gpu-tmastorewait"><code class="docutils literal notranslate"><span class="pre">triton_nvidia_gpu.async_tma_store_wait</span></code> (triton::nvidia_gpu::TMAStoreWait)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id9">Attributes:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#triton-nvidia-gpu-wait-barrier-triton-nvidia-gpu-waitbarrierop"><code class="docutils literal notranslate"><span class="pre">triton_nvidia_gpu.wait_barrier</span></code> (triton::nvidia_gpu::WaitBarrierOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id10">Operands:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#triton-nvidia-gpu-warp-group-dot-triton-nvidia-gpu-warpgroupdotop"><code class="docutils literal notranslate"><span class="pre">triton_nvidia_gpu.warp_group_dot</span></code> (triton::nvidia_gpu::WarpGroupDotOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id11">Attributes:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id12">Operands:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#results">Results:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#triton-nvidia-gpu-warp-group-dot-wait-triton-nvidia-gpu-warpgroupdotwaitop"><code class="docutils literal notranslate"><span class="pre">triton_nvidia_gpu.warp_group_dot_wait</span></code> (triton::nvidia_gpu::WarpGroupDotWaitOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id13">Attributes:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id14">Operands:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id15">Results:</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="NVGPUOps.html">NVGPUOps<!-- Autogenerated by mlir-tblgen; don't manually edit --></a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Programming Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../programming-guide/chapter-1/introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../programming-guide/chapter-2/related-work.html">Related Work</a></li>
<li class="toctree-l1"><a class="reference internal" href="../programming-guide/chapter-3/debugging.html">Debugging Triton</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Triton</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="dialects.html">Triton MLIR Dialects and Ops</a></li>
      <li class="breadcrumb-item active">TritonNvidiaGPUOps<!-- Autogenerated by mlir-tblgen; don't manually edit --></li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/dialects/TritonNvidiaGPUOps.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="tritonnvidiagpuops">
<h1>TritonNvidiaGPUOps<!-- Autogenerated by mlir-tblgen; don't manually edit --><a class="headerlink" href="#tritonnvidiagpuops" title="Link to this heading">¶</a></h1>
<section id="triton-nvidia-gpu-async-tma-copy-global-to-local-triton-nvidia-gpu-asynctmacopyglobaltolocalop">
<h2><code class="docutils literal notranslate"><span class="pre">triton_nvidia_gpu.async_tma_copy_global_to_local</span></code> (triton::nvidia_gpu::AsyncTMACopyGlobalToLocalOp)<a class="headerlink" href="#triton-nvidia-gpu-async-tma-copy-global-to-local-triton-nvidia-gpu-asynctmacopyglobaltolocalop" title="Link to this heading">¶</a></h2>
<p><em>Copy data based on descriptor from global memory to local memory asynchronously</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `triton_nvidia_gpu.async_tma_copy_global_to_local` $desc_ptr `[` $coord `]` $result `,` $barrier `,` $pred
              oilist(`cacheModifier` `=` $cache | `evictionPolicy` `=` $evict)
              attr-dict `:` type($desc_ptr) `,` type($barrier) `-&gt;` type($result)
</pre></div>
</div>
<p>This operation copies data from global memory to local memory
asynchronously.  This is analogue to tt.load except the data are copied to
local memory pointed by the memory descriptor instread of a distributed
tensor. The data copied depends on the global memory descriptor pointed to
by <code class="docutils literal notranslate"><span class="pre">desc_ptr</span></code>.</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">VerifyTensorLayoutsTrait</span></code></p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">MemoryEffectOpInterface</span></code></p>
<section id="attributes">
<h3>Attributes:<a class="headerlink" href="#attributes" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>cache</code></td><td>::mlir::triton::CacheModifierAttr</td><td><details><summary>allowed 32-bit signless integer cases: 1, 2, 3, 4, 5, 6</summary>{{% markdown %}}Enum cases:
* none (`NONE`)
* ca (`CA`)
* cg (`CG`)
* wb (`WB`)
* cs (`CS`)
* wt (`WT`){{% /markdown %}}</details></td></tr>
<tr><td><code>evict</code></td><td>::mlir::triton::EvictionPolicyAttr</td><td><details><summary>allowed 32-bit signless integer cases: 1, 2, 3</summary>{{% markdown %}}Enum cases:
* evict_normal (`NORMAL`)
* evict_first (`EVICT_FIRST`)
* evict_last (`EVICT_LAST`){{% /markdown %}}</details></td></tr>
<tr><td><code>isVolatile</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr>
</table>
</section>
<section id="operands">
<h3>Operands:<a class="headerlink" href="#operands" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">desc_ptr</span></code></p></td>
<td><p>Pointer type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::PointerType</span></code>) in Triton IR type system</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">coord</span></code></p></td>
<td><p>variadic of 32-bit signless integer</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">barrier</span></code></p></td>
<td><p>memory descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::MemDescType</span></code>) in Triton IR type system</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">result</span></code></p></td>
<td><p>memory descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::MemDescType</span></code>) in Triton IR type system</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">pred</span></code></p></td>
<td><p>1-bit signless integer</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="triton-nvidia-gpu-async-tma-copy-local-to-global-triton-nvidia-gpu-asynctmacopylocaltoglobalop">
<h2><code class="docutils literal notranslate"><span class="pre">triton_nvidia_gpu.async_tma_copy_local_to_global</span></code> (triton::nvidia_gpu::AsyncTMACopyLocalToGlobalOp)<a class="headerlink" href="#triton-nvidia-gpu-async-tma-copy-local-to-global-triton-nvidia-gpu-asynctmacopylocaltoglobalop" title="Link to this heading">¶</a></h2>
<p><em>Copy data based on descriptor from local memory to global memory asynchronously</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `triton_nvidia_gpu.async_tma_copy_local_to_global` $desc_ptr `[` $coord `]` $src
              attr-dict `:` type($desc_ptr) `,` type($src)
</pre></div>
</div>
<p>This operation copies data from local memory to global memory
asynchronously.  This is analogue to tt.store except the data are copied from
local memory pointed by the memory descriptor instread of a distributed
tensor. The data copied depends on the global memory descriptor pointed to
by <code class="docutils literal notranslate"><span class="pre">desc_ptr</span></code>.</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">VerifyTensorLayoutsTrait</span></code></p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">MemoryEffectOpInterface</span></code></p>
<section id="id1">
<h3>Operands:<a class="headerlink" href="#id1" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">desc_ptr</span></code></p></td>
<td><p>Pointer type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::PointerType</span></code>) in Triton IR type system</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">coord</span></code></p></td>
<td><p>variadic of 32-bit signless integer</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">src</span></code></p></td>
<td><p>memory descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::MemDescType</span></code>) in Triton IR type system</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="triton-nvidia-gpu-barrier-expect-triton-nvidia-gpu-barrierexpectop">
<h2><code class="docutils literal notranslate"><span class="pre">triton_nvidia_gpu.barrier_expect</span></code> (triton::nvidia_gpu::BarrierExpectOp)<a class="headerlink" href="#triton-nvidia-gpu-barrier-expect-triton-nvidia-gpu-barrierexpectop" title="Link to this heading">¶</a></h2>
<p><em>Signal a barrier of an expected number of bytes to be copied.</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `triton_nvidia_gpu.barrier_expect` $alloc `,` $size attr-dict `,` $pred `:` type($alloc)
</pre></div>
</div>
<p>This signal the barrier that <code class="docutils literal notranslate"><span class="pre">size</span></code> bytes are expected to be copied. The
associated barrier wait will block until the expected number of bytes are copied.</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">VerifyTensorLayoutsTrait</span></code></p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">MemoryEffectOpInterface</span></code></p>
<section id="id2">
<h3>Attributes:<a class="headerlink" href="#id2" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>size</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
</table>
</section>
<section id="id3">
<h3>Operands:<a class="headerlink" href="#id3" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">alloc</span></code></p></td>
<td><p>memory descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::MemDescType</span></code>) in Triton IR type system</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">pred</span></code></p></td>
<td><p>1-bit signless integer</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="triton-nvidia-gpu-cluster-arrive-triton-nvidia-gpu-clusterarriveop">
<h2><code class="docutils literal notranslate"><span class="pre">triton_nvidia_gpu.cluster_arrive</span></code> (triton::nvidia_gpu::ClusterArriveOp)<a class="headerlink" href="#triton-nvidia-gpu-cluster-arrive-triton-nvidia-gpu-clusterarriveop" title="Link to this heading">¶</a></h2>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `triton_nvidia_gpu.cluster_arrive` attr-dict
</pre></div>
</div>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">VerifyTensorLayoutsTrait</span></code></p>
<section id="id4">
<h3>Attributes:<a class="headerlink" href="#id4" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>relaxed</code></td><td>::mlir::IntegerAttr</td><td>1-bit signless integer attribute</td></tr>
</table>
</section>
</section>
<section id="triton-nvidia-gpu-cluster-wait-triton-nvidia-gpu-clusterwaitop">
<h2><code class="docutils literal notranslate"><span class="pre">triton_nvidia_gpu.cluster_wait</span></code> (triton::nvidia_gpu::ClusterWaitOp)<a class="headerlink" href="#triton-nvidia-gpu-cluster-wait-triton-nvidia-gpu-clusterwaitop" title="Link to this heading">¶</a></h2>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `triton_nvidia_gpu.cluster_wait` attr-dict
</pre></div>
</div>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">VerifyTensorLayoutsTrait</span></code></p>
</section>
<section id="triton-nvidia-gpu-fence-async-shared-triton-nvidia-gpu-fenceasyncsharedop">
<h2><code class="docutils literal notranslate"><span class="pre">triton_nvidia_gpu.fence_async_shared</span></code> (triton::nvidia_gpu::FenceAsyncSharedOp)<a class="headerlink" href="#triton-nvidia-gpu-fence-async-shared-triton-nvidia-gpu-fenceasyncsharedop" title="Link to this heading">¶</a></h2>
<p><em>Fence proxy async</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `triton_nvidia_gpu.fence_async_shared` attr-dict
</pre></div>
</div>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">VerifyTensorLayoutsTrait</span></code></p>
<section id="id5">
<h3>Attributes:<a class="headerlink" href="#id5" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>bCluster</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr>
</table>
</section>
</section>
<section id="triton-nvidia-gpu-init-barrier-triton-nvidia-gpu-initbarrierop">
<h2><code class="docutils literal notranslate"><span class="pre">triton_nvidia_gpu.init_barrier</span></code> (triton::nvidia_gpu::InitBarrierOp)<a class="headerlink" href="#triton-nvidia-gpu-init-barrier-triton-nvidia-gpu-initbarrierop" title="Link to this heading">¶</a></h2>
<p><em>Initialize a barrier in the given shared memory allocation.</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `triton_nvidia_gpu.init_barrier` $alloc `,` $count attr-dict `:` type($alloc)
</pre></div>
</div>
<p>Initializes a shared memory allocation with mbarrier information.
<code class="docutils literal notranslate"><span class="pre">alloc</span></code> is a descriptor to the shared memory allocation. <code class="docutils literal notranslate"><span class="pre">count</span></code> is the
number of arrives expected by the barrier.</p>
<p>This lowers to PTX mbarrier.init.shared::cta.b64.</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">VerifyTensorLayoutsTrait</span></code></p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">MemoryEffectOpInterface</span></code></p>
<section id="id6">
<h3>Attributes:<a class="headerlink" href="#id6" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>count</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
</table>
</section>
<section id="id7">
<h3>Operands:<a class="headerlink" href="#id7" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">alloc</span></code></p></td>
<td><p>memory descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::MemDescType</span></code>) in Triton IR type system</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="triton-nvidia-gpu-inval-barrier-triton-nvidia-gpu-invalbarrierop">
<h2><code class="docutils literal notranslate"><span class="pre">triton_nvidia_gpu.inval_barrier</span></code> (triton::nvidia_gpu::InvalBarrierOp)<a class="headerlink" href="#triton-nvidia-gpu-inval-barrier-triton-nvidia-gpu-invalbarrierop" title="Link to this heading">¶</a></h2>
<p><em>Invalidate a barrier allocation.</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `triton_nvidia_gpu.inval_barrier` $alloc attr-dict `:` type($alloc)
</pre></div>
</div>
<p>Invalidate a barrier allocation so that it can be re-used. According to PTX
spec this has to be done before any re-use of the memory used by mbarrier.</p>
<p>https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-mbarrier-inval</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">VerifyTensorLayoutsTrait</span></code></p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">MemoryEffectOpInterface</span></code></p>
<section id="id8">
<h3>Operands:<a class="headerlink" href="#id8" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">alloc</span></code></p></td>
<td><p>memory descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::MemDescType</span></code>) in Triton IR type system</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="triton-nvidia-gpu-async-tma-store-wait-triton-nvidia-gpu-tmastorewait">
<h2><code class="docutils literal notranslate"><span class="pre">triton_nvidia_gpu.async_tma_store_wait</span></code> (triton::nvidia_gpu::TMAStoreWait)<a class="headerlink" href="#triton-nvidia-gpu-async-tma-store-wait-triton-nvidia-gpu-tmastorewait" title="Link to this heading">¶</a></h2>
<p><em>Wait until all the inputs are read.</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `triton_nvidia_gpu.async_tma_store_wait` attr-dict
</pre></div>
</div>
<p>Wait until all the read operations are done from the associated store operations.
This is needed before the shared memory can be written to.</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">VerifyTensorLayoutsTrait</span></code></p>
<section id="id9">
<h3>Attributes:<a class="headerlink" href="#id9" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>pendings</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
</table>
</section>
</section>
<section id="triton-nvidia-gpu-wait-barrier-triton-nvidia-gpu-waitbarrierop">
<h2><code class="docutils literal notranslate"><span class="pre">triton_nvidia_gpu.wait_barrier</span></code> (triton::nvidia_gpu::WaitBarrierOp)<a class="headerlink" href="#triton-nvidia-gpu-wait-barrier-triton-nvidia-gpu-waitbarrierop" title="Link to this heading">¶</a></h2>
<p><em>Wait until the mbarrier phase completes.</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `triton_nvidia_gpu.wait_barrier` $alloc `,` $phase attr-dict `:` type($alloc)
</pre></div>
</div>
<p>Blocks the program progress until the mbarrier object in <code class="docutils literal notranslate"><span class="pre">alloc</span></code> completes
its current phase.</p>
<p>This lowers a waitloop using PTX instruction
mbarrier.try_wait.parity.shared.b64.</p>
<p>The barrier behavior is described here:
https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-asynchronous-copy-completion-mechanisms</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">VerifyTensorLayoutsTrait</span></code></p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">MemoryEffectOpInterface</span></code></p>
<section id="id10">
<h3>Operands:<a class="headerlink" href="#id10" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">alloc</span></code></p></td>
<td><p>memory descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::MemDescType</span></code>) in Triton IR type system</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">phase</span></code></p></td>
<td><p>32-bit signless integer</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="triton-nvidia-gpu-warp-group-dot-triton-nvidia-gpu-warpgroupdotop">
<h2><code class="docutils literal notranslate"><span class="pre">triton_nvidia_gpu.warp_group_dot</span></code> (triton::nvidia_gpu::WarpGroupDotOp)<a class="headerlink" href="#triton-nvidia-gpu-warp-group-dot-triton-nvidia-gpu-warpgroupdotop" title="Link to this heading">¶</a></h2>
<p><em>Warp group dot</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `triton_nvidia_gpu.warp_group_dot` $a`,` $b`,` $c (`,` $useC^)? attr-dict `:` type($a) `*` type($b) `-&gt;` type($d)
</pre></div>
</div>
<p>$d = matrix_multiply($a, $b) + $c. For docs on InputPrecisionAttr, see TT_DotOp</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">DotLike</span></code>, <code class="docutils literal notranslate"><span class="pre">VerifyTensorLayoutsTrait</span></code></p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">InferTypeOpInterface</span></code>, <code class="docutils literal notranslate"><span class="pre">MemoryEffectOpInterface</span></code></p>
<section id="id11">
<h3>Attributes:<a class="headerlink" href="#id11" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>inputPrecision</code></td><td>::mlir::triton::InputPrecisionAttr</td><td><details><summary>allowed 32-bit signless integer cases: 0, 1, 2</summary>{{% markdown %}}Enum cases:
* tf32 (`TF32`)
* tf32x3 (`TF32x3`)
* ieee (`IEEE`){{% /markdown %}}</details></td></tr>
<tr><td><code>maxNumImpreciseAcc</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
<tr><td><code>isAsync</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr>
</table>
</section>
<section id="id12">
<h3>Operands:<a class="headerlink" href="#id12" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">a</span></code></p></td>
<td><p>TensorOrMemDesc instance</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">b</span></code></p></td>
<td><p>TensorOrMemDesc instance</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">c</span></code></p></td>
<td><p>ranked tensor of floating-point or integer values</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">useC</span></code></p></td>
<td><p>1-bit signless integer</p></td>
</tr>
</tbody>
</table>
</section>
<section id="results">
<h3>Results:<a class="headerlink" href="#results" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Result</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">d</span></code></p></td>
<td><p>ranked tensor of floating-point or integer values</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="triton-nvidia-gpu-warp-group-dot-wait-triton-nvidia-gpu-warpgroupdotwaitop">
<h2><code class="docutils literal notranslate"><span class="pre">triton_nvidia_gpu.warp_group_dot_wait</span></code> (triton::nvidia_gpu::WarpGroupDotWaitOp)<a class="headerlink" href="#triton-nvidia-gpu-warp-group-dot-wait-triton-nvidia-gpu-warpgroupdotwaitop" title="Link to this heading">¶</a></h2>
<p><em>Warp group dot wait</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `triton_nvidia_gpu.warp_group_dot_wait` $inputs attr-dict `:` type($inputs)
</pre></div>
</div>
<p>Waits until there are $pendings or fewer outstanding async dot operations.</p>
<p>$inputs must be the tensors corresponding to the async dot ops that we’re
waiting on.  For example, if there are N pending async dot ops and we call
<code class="docutils literal notranslate"><span class="pre">warp_group_dot_wait</span> <span class="pre">1</span></code>, then $inputs must be the result of the first dot op.</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">VerifyTensorLayoutsTrait</span></code></p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">InferTypeOpInterface</span></code></p>
<section id="id13">
<h3>Attributes:<a class="headerlink" href="#id13" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>pendings</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
</table>
</section>
<section id="id14">
<h3>Operands:<a class="headerlink" href="#id14" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">inputs</span></code></p></td>
<td><p>variadic of TensorOrMemDesc instance</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id15">
<h3>Results:<a class="headerlink" href="#id15" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Result</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">outputs</span></code></p></td>
<td><p>variadic of TensorOrMemDesc instance</p></td>
</tr>
</tbody>
</table>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="TritonOps.html" class="btn btn-neutral float-left" title="TritonOps" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="NVGPUOps.html" class="btn btn-neutral float-right" title="NVGPUOps" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Philippe Tillet.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>