

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>TritonAMDGPUOps &mdash; Triton  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=9edc463e" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />

  
      <script src="../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="TritonGPUOps" href="TritonGPUOps.html" />
    <link rel="prev" title="TritonInstrumentOps" href="TritonInstrumentOps.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Triton
              <img src="https://cdn.openai.com/triton/assets/triton-logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../getting-started/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting-started/tutorials/index.html">Tutorials</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../python-api/triton.html">triton</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python-api/triton.language.html">triton.language</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python-api/triton.testing.html">triton.testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python-api/triton-semantics.html">Triton Semantics</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Triton MLIR Dialects</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="dialects.html">Triton MLIR Dialects and Ops</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="GluonDialect.html">‘gluon’ Dialect</a></li>
<li class="toctree-l2"><a class="reference internal" href="TritonNvidiaGPUDialect.html">‘ttng’ Dialect</a></li>
<li class="toctree-l2"><a class="reference internal" href="TritonGPUDialect.html">‘ttg’ Dialect</a></li>
<li class="toctree-l2"><a class="reference internal" href="ProtonDialect.html">‘proton’ Dialect</a></li>
<li class="toctree-l2"><a class="reference internal" href="NVGPUDialect.html">‘nvg’ Dialect</a></li>
<li class="toctree-l2"><a class="reference internal" href="ProtonGPUDialect.html">‘proton_gpu’ Dialect</a></li>
<li class="toctree-l2"><a class="reference internal" href="NVWSDialect.html">‘nvws’ Dialect</a></li>
<li class="toctree-l2"><a class="reference internal" href="TritonDialect.html">‘tt’ Dialect</a></li>
<li class="toctree-l2"><a class="reference internal" href="TritonInstrumentDialect.html">‘tti’ Dialect</a></li>
<li class="toctree-l2"><a class="reference internal" href="TritonAMDGPUDialect.html">‘amdg’ Dialect</a></li>
<li class="toctree-l2"><a class="reference internal" href="TritonInstrumentOps.html">TritonInstrumentOps<!-- Autogenerated by mlir-tblgen; don't manually edit --></a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">TritonAMDGPUOps<!-- Autogenerated by mlir-tblgen; don't manually edit --></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#amdg-arrive-barrier-triton-amdgpu-arrivebarrierop"><code class="docutils literal notranslate"><span class="pre">amdg.arrive_barrier</span></code> (triton::amdgpu::ArriveBarrierOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#attributes">Attributes:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#operands">Operands:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#results">Results:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-async-copy-local-to-global-triton-amdgpu-asynccopylocaltoglobalop"><code class="docutils literal notranslate"><span class="pre">amdg.async_copy_local_to_global</span></code> (triton::amdgpu::AsyncCopyLocalToGlobalOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id1">Attributes:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id2">Operands:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id3">Results:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-async-copy-mbarrier-arrive-triton-amdgpu-asynccopymbarrierarriveop"><code class="docutils literal notranslate"><span class="pre">amdg.async_copy_mbarrier_arrive</span></code> (triton::amdgpu::AsyncCopyMbarrierArriveOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id4">Operands:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-async-tdm-copy-global-to-local-triton-amdgpu-asynctdmcopyglobaltolocalop"><code class="docutils literal notranslate"><span class="pre">amdg.async_tdm_copy_global_to_local</span></code> (triton::amdgpu::AsyncTDMCopyGlobalToLocalOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id5">Operands:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id6">Results:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-async-tdm-copy-local-to-global-triton-amdgpu-asynctdmcopylocaltoglobalop"><code class="docutils literal notranslate"><span class="pre">amdg.async_tdm_copy_local_to_global</span></code> (triton::amdgpu::AsyncTDMCopyLocalToGlobalOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id7">Operands:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-async-tdm-gather-triton-amdgpu-asynctdmgatherop"><code class="docutils literal notranslate"><span class="pre">amdg.async_tdm_gather</span></code> (triton::amdgpu::AsyncTDMGatherOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id8">Operands:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id9">Results:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-async-tdm-intrinsic-wait-triton-amdgpu-asynctdmintrinsicwait"><code class="docutils literal notranslate"><span class="pre">amdg.async_tdm_intrinsic_wait</span></code> (triton::amdgpu::AsyncTDMIntrinsicWait)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id10">Attributes:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id11">Operands:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id12">Results:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-async-tdm-scatter-triton-amdgpu-asynctdmscatterop"><code class="docutils literal notranslate"><span class="pre">amdg.async_tdm_scatter</span></code> (triton::amdgpu::AsyncTDMScatterOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id13">Operands:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id14">Results:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-async-tdm-wait-triton-amdgpu-asynctdmwait"><code class="docutils literal notranslate"><span class="pre">amdg.async_tdm_wait</span></code> (triton::amdgpu::AsyncTDMWait)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id15">Attributes:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id16">Operands:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id17">Results:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-async-wait-triton-amdgpu-asyncwaitop"><code class="docutils literal notranslate"><span class="pre">amdg.async_wait</span></code> (triton::amdgpu::AsyncWaitOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id18">Attributes:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id19">Operands:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id20">Results:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-buffer-atomic-cas-triton-amdgpu-bufferatomiccasop"><code class="docutils literal notranslate"><span class="pre">amdg.buffer_atomic_cas</span></code> (triton::amdgpu::BufferAtomicCASOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id21">Attributes:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id22">Operands:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id23">Results:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-buffer-atomic-rmw-triton-amdgpu-bufferatomicrmwop"><code class="docutils literal notranslate"><span class="pre">amdg.buffer_atomic_rmw</span></code> (triton::amdgpu::BufferAtomicRMWOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id24">Attributes:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id25">Operands:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id26">Results:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-buffer-load-triton-amdgpu-bufferloadop"><code class="docutils literal notranslate"><span class="pre">amdg.buffer_load</span></code> (triton::amdgpu::BufferLoadOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id27">Attributes:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id28">Operands:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id29">Results:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-buffer-load-to-local-triton-amdgpu-bufferloadtolocalop"><code class="docutils literal notranslate"><span class="pre">amdg.buffer_load_to_local</span></code> (triton::amdgpu::BufferLoadToLocalOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id30">Attributes:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id31">Operands:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id32">Results:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-buffer-store-triton-amdgpu-bufferstoreop"><code class="docutils literal notranslate"><span class="pre">amdg.buffer_store</span></code> (triton::amdgpu::BufferStoreOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id33">Attributes:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id34">Operands:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-cluster-barrier-arrive-triton-amdgpu-clusterbarrierarriveop"><code class="docutils literal notranslate"><span class="pre">amdg.cluster_barrier_arrive</span></code> (triton::amdgpu::ClusterBarrierArriveOp)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-cluster-barrier-wait-triton-amdgpu-clusterbarrierwaitop"><code class="docutils literal notranslate"><span class="pre">amdg.cluster_barrier_wait</span></code> (triton::amdgpu::ClusterBarrierWaitOp)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-concat-triton-amdgpu-concatop"><code class="docutils literal notranslate"><span class="pre">amdg.concat</span></code> (triton::amdgpu::ConcatOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id35">Operands:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id36">Results:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-cond-barrier-triton-amdgpu-condbarrierop"><code class="docutils literal notranslate"><span class="pre">amdg.cond_barrier</span></code> (triton::amdgpu::CondBarrierOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id37">Operands:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-extract-slice-triton-amdgpu-extractsliceop"><code class="docutils literal notranslate"><span class="pre">amdg.extract_slice</span></code> (triton::amdgpu::ExtractSliceOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id38">Attributes:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id39">Operands:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id40">Results:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-in-thread-transpose-triton-amdgpu-inthreadtransposeop"><code class="docutils literal notranslate"><span class="pre">amdg.in_thread_transpose</span></code> (triton::amdgpu::InThreadTransposeOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id41">Operands:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id42">Results:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-init-barrier-triton-amdgpu-initbarrierop"><code class="docutils literal notranslate"><span class="pre">amdg.init_barrier</span></code> (triton::amdgpu::InitBarrierOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id43">Attributes:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id44">Operands:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-instruction-sched-hint-triton-amdgpu-instructionschedhint"><code class="docutils literal notranslate"><span class="pre">amdg.instruction_sched_hint</span></code> (triton::amdgpu::InstructionSchedHint)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id45">Attributes:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-local-load-packed-tranposed-triton-amdgpu-localloadpackedtransposedop"><code class="docutils literal notranslate"><span class="pre">amdg.local_load_packed_tranposed</span></code> (triton::amdgpu::LocalLoadPackedTransposedOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id46">Operands:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id47">Results:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-masked-load-triton-amdgpu-maskedloadop"><code class="docutils literal notranslate"><span class="pre">amdg.masked_load</span></code> (triton::amdgpu::MaskedLoadOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id48">Attributes:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id49">Operands:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id50">Results:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-masked-store-triton-amdgpu-maskedstoreop"><code class="docutils literal notranslate"><span class="pre">amdg.masked_store</span></code> (triton::amdgpu::MaskedStoreOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id51">Attributes:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id52">Operands:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-memory-counter-wait-triton-amdgpu-memorycounterwaitop"><code class="docutils literal notranslate"><span class="pre">amdg.memory_counter_wait</span></code> (triton::amdgpu::MemoryCounterWaitOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id53">Attributes:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-scaled-upcast-fp4-triton-amdgpu-scaledupcastfp4op"><code class="docutils literal notranslate"><span class="pre">amdg.scaled_upcast_fp4</span></code> (triton::amdgpu::ScaledUpcastFp4Op)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id54">Attributes:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id55">Operands:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id56">Results:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-scaled-upcast-fp8-triton-amdgpu-scaledupcastfp8op"><code class="docutils literal notranslate"><span class="pre">amdg.scaled_upcast_fp8</span></code> (triton::amdgpu::ScaledUpcastFp8Op)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id57">Operands:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id58">Results:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-tdm-prefetch-triton-amdgpu-tdmprefetchop"><code class="docutils literal notranslate"><span class="pre">amdg.tdm_prefetch</span></code> (triton::amdgpu::TDMPrefetchOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id59">Attributes:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id60">Operands:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id61">Results:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-upcast-mxfp-triton-amdgpu-upcastmxfpop"><code class="docutils literal notranslate"><span class="pre">amdg.upcast_mxfp</span></code> (triton::amdgpu::UpcastMXFPOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id62">Attributes:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id63">Operands:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id64">Results:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#amdg-wait-barrier-triton-amdgpu-waitbarrierop"><code class="docutils literal notranslate"><span class="pre">amdg.wait_barrier</span></code> (triton::amdgpu::WaitBarrierOp)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id65">Operands:</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="TritonGPUOps.html">TritonGPUOps<!-- Autogenerated by mlir-tblgen; don't manually edit --></a></li>
<li class="toctree-l2"><a class="reference internal" href="ProtonGPUOps.html">ProtonGPUOps<!-- Autogenerated by mlir-tblgen; don't manually edit --></a></li>
<li class="toctree-l2"><a class="reference internal" href="ProtonOps.html">ProtonOps<!-- Autogenerated by mlir-tblgen; don't manually edit --></a></li>
<li class="toctree-l2"><a class="reference internal" href="GluonOps.html">GluonOps<!-- Autogenerated by mlir-tblgen; don't manually edit --></a></li>
<li class="toctree-l2"><a class="reference internal" href="TritonOps.html">TritonOps<!-- Autogenerated by mlir-tblgen; don't manually edit --></a></li>
<li class="toctree-l2"><a class="reference internal" href="TritonNvidiaGPUOps.html">TritonNvidiaGPUOps<!-- Autogenerated by mlir-tblgen; don't manually edit --></a></li>
<li class="toctree-l2"><a class="reference internal" href="NVGPUOps.html">NVGPUOps<!-- Autogenerated by mlir-tblgen; don't manually edit --></a></li>
<li class="toctree-l2"><a class="reference internal" href="NVWSOps.html">NVWSOps<!-- Autogenerated by mlir-tblgen; don't manually edit --></a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Programming Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../programming-guide/chapter-1/introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../programming-guide/chapter-2/related-work.html">Related Work</a></li>
<li class="toctree-l1"><a class="reference internal" href="../programming-guide/chapter-3/debugging.html">Debugging Triton</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Triton</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="dialects.html">Triton MLIR Dialects and Ops</a></li>
      <li class="breadcrumb-item active">TritonAMDGPUOps<!-- Autogenerated by mlir-tblgen; don't manually edit --></li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/dialects/TritonAMDGPUOps.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="tritonamdgpuops">
<h1>TritonAMDGPUOps<!-- Autogenerated by mlir-tblgen; don't manually edit --><a class="headerlink" href="#tritonamdgpuops" title="Link to this heading">¶</a></h1>
<section id="amdg-arrive-barrier-triton-amdgpu-arrivebarrierop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.arrive_barrier</span></code> (triton::amdgpu::ArriveBarrierOp)<a class="headerlink" href="#amdg-arrive-barrier-triton-amdgpu-arrivebarrierop" title="Link to this heading">¶</a></h2>
<p><em>Perform the arrive operation on an mbarrier</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.arrive_barrier` $alloc `,` $count attr-dict `:` qualified(type($alloc)) `-&gt;` type($result)
</pre></div>
</div>
<p>Performs the “arrive” operation on an mbarrier object in shared memory. The operation requires a <code class="docutils literal notranslate"><span class="pre">count</span></code> attribute
of at least 1, and decreases the pending arrival count of the mbarrier by the specific count. If the pending count reaches
zero, the phase changes (is decremented in a wraparound manner) and the pending count is reloaded with the init count value. Returns the phase
parity (0 for even, 1 for odd) of the mbarrier object prior to the “arrive” operation.</p>
<p>Example:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>ttag.arrive_barrier %barrier, 2 : !ttg.memdesc&lt;1xi64, #shared, #smem, mutable&gt;
</pre></div>
</div>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">InferTypeOpInterface</span></code></p>
<section id="attributes">
<h3>Attributes:<a class="headerlink" href="#attributes" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>count</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
</table>
</section>
<section id="operands">
<h3>Operands:<a class="headerlink" href="#operands" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">alloc</span></code></p></td>
<td><p>memory descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::gpu::MemDescType</span></code>) in Triton IR type system</p></td>
</tr>
</tbody>
</table>
</section>
<section id="results">
<h3>Results:<a class="headerlink" href="#results" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Result</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">result</span></code></p></td>
<td><p>32-bit signless integer</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-async-copy-local-to-global-triton-amdgpu-asynccopylocaltoglobalop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.async_copy_local_to_global</span></code> (triton::amdgpu::AsyncCopyLocalToGlobalOp)<a class="headerlink" href="#amdg-async-copy-local-to-global-triton-amdgpu-asynccopylocaltoglobalop" title="Link to this heading">¶</a></h2>
<p><em>Copy data from local memory to global memory asynchronously</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.async_copy_local_to_global` $src `,` $dst (`mask` $mask^)?
              oilist(`cacheModifier` `=` $cache | `evictionPolicy` `=` $evict)
              attr-dict `:` qualified(type($src)) `-&gt;` type($dst)
</pre></div>
</div>
<p>This operation copies data from local memory to global memory asynchronously.
This is analogue to tt.store except the data are copied from local memory pointed
to by the memory descriptor instead of a distributed tensor.
Contiguity is the maximum number of elements that can be stored in a single vector with
the given layout and mask.
This allows op to use async_copy_local_to_global even if the alignment cannot be proven based on IR.</p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">InferTypeOpInterface</span></code></p>
<section id="id1">
<h3>Attributes:<a class="headerlink" href="#id1" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>cache</code></td><td>::mlir::triton::CacheModifierAttr</td><td>allowed 32-bit signless integer cases: 1, 2, 3, 4, 5, 6, 7</td></tr>
<tr><td><code>evict</code></td><td>::mlir::triton::EvictionPolicyAttr</td><td>allowed 32-bit signless integer cases: 1, 2, 3</td></tr>
<tr><td><code>contiguity</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
</table>
</section>
<section id="id2">
<h3>Operands:<a class="headerlink" href="#id2" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">src</span></code></p></td>
<td><p>memory descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::gpu::MemDescType</span></code>) in Triton IR type system</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">dst</span></code></p></td>
<td><p>ranked tensor of ptr values</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">mask</span></code></p></td>
<td><p>tensor of 1-bit signless integer values</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id3">
<h3>Results:<a class="headerlink" href="#id3" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Result</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">token</span></code></p></td>
<td><p>async token type</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-async-copy-mbarrier-arrive-triton-amdgpu-asynccopymbarrierarriveop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.async_copy_mbarrier_arrive</span></code> (triton::amdgpu::AsyncCopyMbarrierArriveOp)<a class="headerlink" href="#amdg-async-copy-mbarrier-arrive-triton-amdgpu-asynccopymbarrierarriveop" title="Link to this heading">¶</a></h2>
<p><em>Arrive on mbarrier once all previously issued copies are completed</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.async_copy_mbarrier_arrive` $barrier attr-dict `:` qualified(type($barrier))
</pre></div>
</div>
<p>Performs the “async arrive” operation by decrementing pending account by 1 when all previous async load to LDS (particularly, not TDM) have completed.
The instruction itself is asynchronous; it returns immediately. Decrements the barrier pending count. The update value for decrementing is fixed at 1.
If the pending count becomes zero, the phase changes (is decremented in a wraparound manner) and the pending count is reloaded with the init count value.</p>
<section id="id4">
<h3>Operands:<a class="headerlink" href="#id4" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">barrier</span></code></p></td>
<td><p>memory descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::gpu::MemDescType</span></code>) in Triton IR type system</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-async-tdm-copy-global-to-local-triton-amdgpu-asynctdmcopyglobaltolocalop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.async_tdm_copy_global_to_local</span></code> (triton::amdgpu::AsyncTDMCopyGlobalToLocalOp)<a class="headerlink" href="#amdg-async-tdm-copy-global-to-local-triton-amdgpu-asynctdmcopyglobaltolocalop" title="Link to this heading">¶</a></h2>
<p><em>Copy data based on descriptor from global memory to local memory asynchronously</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.async_tdm_copy_global_to_local` $desc `[` $indices `]` `into` $result `,` $pred (`,` `barrier` `=` $barrier^)?
              attr-dict `:` qualified(type($desc)) (`,` qualified(type($barrier))^)? `-&gt;` qualified(type($result))
</pre></div>
</div>
<p>This operation copies data from global memory to local memory
asynchronously. This is analogue to tt.load except the data are copied to
local memory pointed by <code class="docutils literal notranslate"><span class="pre">result</span></code> instead of a distributed tensor. The data
copied depends on the global memory pointed to by <code class="docutils literal notranslate"><span class="pre">desc</span></code>. Set <code class="docutils literal notranslate"><span class="pre">pred</span></code> to
false will disable the copy. This operation does not support shared memory
swizzling.
The operation can also take an optional 64bit LDS barrier address, in which case
it sends an “LDS atomic arrive” to signal its completion.</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">AttrSizedOperandSegments</span></code></p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">InferTypeOpInterface</span></code></p>
<section id="id5">
<h3>Operands:<a class="headerlink" href="#id5" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">desc</span></code></p></td>
<td><p>Tensor descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::TensorDescType</span></code>) in Triton IR type system</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">indices</span></code></p></td>
<td><p>variadic of 32-bit signless integer</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">result</span></code></p></td>
<td><p>memory descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::gpu::MemDescType</span></code>) in Triton IR type system</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">pred</span></code></p></td>
<td><p>32-bit signless integer</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">barrier</span></code></p></td>
<td><p>memory descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::gpu::MemDescType</span></code>) in Triton IR type system</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id6">
<h3>Results:<a class="headerlink" href="#id6" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Result</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">token</span></code></p></td>
<td><p>async token type</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-async-tdm-copy-local-to-global-triton-amdgpu-asynctdmcopylocaltoglobalop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.async_tdm_copy_local_to_global</span></code> (triton::amdgpu::AsyncTDMCopyLocalToGlobalOp)<a class="headerlink" href="#amdg-async-tdm-copy-local-to-global-triton-amdgpu-asynctdmcopylocaltoglobalop" title="Link to this heading">¶</a></h2>
<p><em>Copy data based on descriptor from local memory to global memory asynchronously</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.async_tdm_copy_local_to_global` $desc `[` $indices `]` `from` $src (`,` `barrier` `=` $barrier^)?
              attr-dict `:` qualified(type($src)) (`,` qualified(type($barrier))^)? `-&gt;` qualified(type($desc))
</pre></div>
</div>
<p>This operation copies data from local memory to global memory
asynchronously. This is analogue to tt.store except the data are copied from
local memory pointed by <code class="docutils literal notranslate"><span class="pre">src</span></code> instead of a distributed tensor. The copy
destination depends on the global memory pointed to by <code class="docutils literal notranslate"><span class="pre">desc</span></code>. This
operation does not support shared memory padding or swizzling.
The operation can also take an optional 64bit LDS barrier address, in which case
it sends an “LDS atomic arrive” to signal its completion.</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">AttrSizedOperandSegments</span></code></p>
<section id="id7">
<h3>Operands:<a class="headerlink" href="#id7" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">desc</span></code></p></td>
<td><p>Tensor descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::TensorDescType</span></code>) in Triton IR type system</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">indices</span></code></p></td>
<td><p>variadic of 32-bit signless integer</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">src</span></code></p></td>
<td><p>memory descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::gpu::MemDescType</span></code>) in Triton IR type system</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">barrier</span></code></p></td>
<td><p>memory descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::gpu::MemDescType</span></code>) in Triton IR type system</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-async-tdm-gather-triton-amdgpu-asynctdmgatherop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.async_tdm_gather</span></code> (triton::amdgpu::AsyncTDMGatherOp)<a class="headerlink" href="#amdg-async-tdm-gather-triton-amdgpu-asynctdmgatherop" title="Link to this heading">¶</a></h2>
<p><em>Gather data from non-contiguous global memory rows to local memory asynchronously</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.async_tdm_gather` $desc `[` $src_row_indices `,` $src_col_offset `]` `to` $dst (`,` `barrier` `=` $barrier^)?
              attr-dict `:` qualified(type($src_row_indices)) `,` qualified(type($dst)) (`,` qualified(type($barrier))^)? `-&gt;` qualified(type($desc))
</pre></div>
</div>
<p>This operation gathers data from non-contiguous rows in global memory to local
memory using TDM gather mode.
Unlike the regular async_tdm_copy_global_to_local which reads from contiguous memory,
this operation uses src_row_indices to specify which rows in global memory to read from.</p>
<p>The descriptor must be 2D. The src_row_indices specify which rows in global memory
to read from. The element type of src_row_indices determines the index size:</p>
<ul class="simple">
<li><p>I16: 16-bit indices, up to 16 rows per instruction</p></li>
<li><p>I32: 32-bit indices, up to 8 rows per instruction
If more rows are needed, multiple TDM instructions will be issued.</p></li>
</ul>
<p>The src_col_offset specifies the starting column in the source tensor for
all gathered rows.</p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">InferTypeOpInterface</span></code></p>
<section id="id8">
<h3>Operands:<a class="headerlink" href="#id8" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">desc</span></code></p></td>
<td><p>Tensor descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::TensorDescType</span></code>) in Triton IR type system</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">src_row_indices</span></code></p></td>
<td><p>tensor of 16-bit signless integer or 32-bit signless integer values</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">src_col_offset</span></code></p></td>
<td><p>32-bit signless integer</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">dst</span></code></p></td>
<td><p>memory descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::gpu::MemDescType</span></code>) in Triton IR type system</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">barrier</span></code></p></td>
<td><p>memory descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::gpu::MemDescType</span></code>) in Triton IR type system</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id9">
<h3>Results:<a class="headerlink" href="#id9" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Result</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">token</span></code></p></td>
<td><p>async token type</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-async-tdm-intrinsic-wait-triton-amdgpu-asynctdmintrinsicwait">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.async_tdm_intrinsic_wait</span></code> (triton::amdgpu::AsyncTDMIntrinsicWait)<a class="headerlink" href="#amdg-async-tdm-intrinsic-wait-triton-amdgpu-asynctdmintrinsicwait" title="Link to this heading">¶</a></h2>
<p><em>Wait until there are less than or equal to the given number of outstanding TDM intrinsics</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.async_tdm_intrinsic_wait` ($asyncToken^)? attr-dict
</pre></div>
</div>
<p>This operation waits until there are less than or equal to the given number
of outstanding TDM intrinsics (assembly instructions). This is necessary to
ensure that data is available in LDS (load, gather) or HBM (store, scatter)
before it is used.</p>
<p>Unlike AsyncTDMWait which counts IR operations, this operation counts the
actual number of TDM assembly instructions (e.g., tensor_load_to_lds,
tensor_store_from_lds) that are emitted. Which is required for the lowering
to LLVM.</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">MemWaitOpTrait</span></code></p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">InferTypeOpInterface</span></code></p>
<section id="id10">
<h3>Attributes:<a class="headerlink" href="#id10" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>count</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
</table>
</section>
<section id="id11">
<h3>Operands:<a class="headerlink" href="#id11" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">asyncToken</span></code></p></td>
<td><p>variadic of async token type</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id12">
<h3>Results:<a class="headerlink" href="#id12" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Result</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">retToken</span></code></p></td>
<td><p>async token type</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-async-tdm-scatter-triton-amdgpu-asynctdmscatterop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.async_tdm_scatter</span></code> (triton::amdgpu::AsyncTDMScatterOp)<a class="headerlink" href="#amdg-async-tdm-scatter-triton-amdgpu-asynctdmscatterop" title="Link to this heading">¶</a></h2>
<p><em>Scatter data from local memory to non-contiguous global memory rows asynchronously</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.async_tdm_scatter` $desc `[` $dst_row_indices `,` $dst_col_offset `]` `from` $src (`,` `barrier` `=` $barrier^)?
              attr-dict `:` qualified(type($dst_row_indices)) `,` qualified(type($src)) (`,` qualified(type($barrier))^)? `-&gt;` qualified(type($desc))
</pre></div>
</div>
<p>This operation scatters data from local memory to non-contiguous rows in global
memory using TDM scatter mode.
Unlike the regular async_tdm_copy_local_to_global which copies to contiguous memory,
this operation uses dst_row_indices to specify which rows in global memory to write to.</p>
<p>The descriptor must be 2D. The dst_row_indices specify which rows in global memory
to write to. The element type of dst_row_indices determines the index size:</p>
<ul class="simple">
<li><p>I16: 16-bit indices, up to 16 rows per instruction</p></li>
<li><p>I32: 32-bit indices, up to 8 rows per instruction
If more rows are needed, multiple TDM instructions will be issued.</p></li>
</ul>
<p>The dst_col_offset specifies the starting column in the destination tensor for
all scattered rows.</p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">InferTypeOpInterface</span></code></p>
<section id="id13">
<h3>Operands:<a class="headerlink" href="#id13" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">desc</span></code></p></td>
<td><p>Tensor descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::TensorDescType</span></code>) in Triton IR type system</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">dst_row_indices</span></code></p></td>
<td><p>tensor of 16-bit signless integer or 32-bit signless integer values</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">dst_col_offset</span></code></p></td>
<td><p>32-bit signless integer</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">src</span></code></p></td>
<td><p>memory descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::gpu::MemDescType</span></code>) in Triton IR type system</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">barrier</span></code></p></td>
<td><p>memory descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::gpu::MemDescType</span></code>) in Triton IR type system</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id14">
<h3>Results:<a class="headerlink" href="#id14" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Result</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">retToken</span></code></p></td>
<td><p>async token type</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-async-tdm-wait-triton-amdgpu-asynctdmwait">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.async_tdm_wait</span></code> (triton::amdgpu::AsyncTDMWait)<a class="headerlink" href="#amdg-async-tdm-wait-triton-amdgpu-asynctdmwait" title="Link to this heading">¶</a></h2>
<p><em>Wait until there are less than or equal to the given number of outstanding TDM operations</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.async_tdm_wait` $asyncToken attr-dict
</pre></div>
</div>
<p>This operation waits until there are less than or equal to the given number
of outstanding async TDM operations.
This is necessary to ensure that data is available in the LDS (load, gather)
or HBM (store, scatter) before it is used.</p>
<p>This operation counts the number of TDM IR operations (AsyncTDMCopyGlobalToLocalOp,
AsyncTDMCopyLocalToGlobalOp, AsyncTDMScatterOp, AsyncTDMGatherOp).</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">MemWaitOpTrait</span></code></p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">InferTypeOpInterface</span></code></p>
<section id="id15">
<h3>Attributes:<a class="headerlink" href="#id15" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>num</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
</table>
</section>
<section id="id16">
<h3>Operands:<a class="headerlink" href="#id16" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">asyncToken</span></code></p></td>
<td><p>variadic of async token type</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id17">
<h3>Results:<a class="headerlink" href="#id17" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Result</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">retToken</span></code></p></td>
<td><p>async token type</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-async-wait-triton-amdgpu-asyncwaitop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.async_wait</span></code> (triton::amdgpu::AsyncWaitOp)<a class="headerlink" href="#amdg-async-wait-triton-amdgpu-asyncwaitop" title="Link to this heading">¶</a></h2>
<p><em>Wait until there are less than or equal to the given number of outstanding async intrinsics</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.async_wait` ($asyncToken^)? attr-dict
</pre></div>
</div>
<p>Similar to ttg.async_wait but instead of waiting on oustanding ttg.async_commit_groups
this op waits on the number of outstanding async instructions/intrinsics as required for the
lowering to LLVM on the AMD backend.</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">MemWaitOpTrait</span></code></p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">InferTypeOpInterface</span></code></p>
<section id="id18">
<h3>Attributes:<a class="headerlink" href="#id18" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>num_inst</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
</table>
</section>
<section id="id19">
<h3>Operands:<a class="headerlink" href="#id19" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">asyncToken</span></code></p></td>
<td><p>variadic of async token type</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id20">
<h3>Results:<a class="headerlink" href="#id20" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Result</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">retToken</span></code></p></td>
<td><p>async token type</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-buffer-atomic-cas-triton-amdgpu-bufferatomiccasop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.buffer_atomic_cas</span></code> (triton::amdgpu::BufferAtomicCASOp)<a class="headerlink" href="#amdg-buffer-atomic-cas-triton-amdgpu-bufferatomiccasop" title="Link to this heading">¶</a></h2>
<p><em>Atomic CAS op which does compare-exchange to a scalar base pointer and a tensor offset</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.buffer_atomic_cas` $sem `,` $scope `,` $cmp `,` $val `,` $ptr `[` $offsets `]`
              (`stride` `=` $stride^)?
              attr-dict `:` type($result)
</pre></div>
</div>
<p>AMD Buffer Atomic CAS operation. Buffer atomics are similar to normal atomics, but access global memory via a
scalar base pointer and a tensor of offsets instead of a tensor of pointers.
Similar to TT_AtomicCASOp: Buffer atomic CAS op loads data at $ptr, and stores $val to $ptr atomically if value at $ptr equals $cmp, with
the specified memory semantics and scope. Atomic CAS ops return the pre-op value if used, otherwise the value is implicitly dropped.
Stride is the distance between the beginning of contiguous memory chunks. When performing a CAS, the <code class="docutils literal notranslate"><span class="pre">stride</span></code> is
the address difference between the first elements of each row in bytes. Compiler tries to obtain the <code class="docutils literal notranslate"><span class="pre">stride</span></code>
when it converts to the buffer ops because it is important for optimizing the cache memory access.</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">SameLoadStoreOperandsAndResultEncoding</span></code></p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">BufferOpInterface</span></code></p>
<section id="id21">
<h3>Attributes:<a class="headerlink" href="#id21" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>sem</code></td><td>::mlir::triton::MemSemanticAttr</td><td>allowed 32-bit signless integer cases: 1, 2, 3, 4</td></tr>
<tr><td><code>scope</code></td><td>::mlir::triton::MemSyncScopeAttr</td><td>allowed 32-bit signless integer cases: 1, 2, 3</td></tr>
</table>
</section>
<section id="id22">
<h3>Operands:<a class="headerlink" href="#id22" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">ptr</span></code></p></td>
<td><p>ptr</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">offsets</span></code></p></td>
<td><p>tensor of 32-bit signless integer values</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">cmp</span></code></p></td>
<td><p>ranked tensor of floating-point or integer or ptr values</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">val</span></code></p></td>
<td><p>ranked tensor of floating-point or integer or ptr values</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">stride</span></code></p></td>
<td><p>32-bit signless integer</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id23">
<h3>Results:<a class="headerlink" href="#id23" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Result</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">result</span></code></p></td>
<td><p>ranked tensor of floating-point or integer or ptr values</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-buffer-atomic-rmw-triton-amdgpu-bufferatomicrmwop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.buffer_atomic_rmw</span></code> (triton::amdgpu::BufferAtomicRMWOp)<a class="headerlink" href="#amdg-buffer-atomic-rmw-triton-amdgpu-bufferatomicrmwop" title="Link to this heading">¶</a></h2>
<p><em>Atomic RMW op which reads, modifies, and writes to a scalar base pointer and a tensor offset</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.buffer_atomic_rmw` $atomic_rmw_op `,` $sem `,` $scope `,` $value `,` $ptr `[` $offsets `]` (`,` $mask^)?
              (`stride` `=` $stride^)?
              attr-dict `:` type($result)
</pre></div>
</div>
<p>AMD Buffer atomic RMW operation. Buffer atomics are similar to normal atomics, but access global memory via a
scalar base pointer and a tensor of offsets instead of a tensor of pointers.
Similar to other buffer ops, the <code class="docutils literal notranslate"><span class="pre">mask</span></code> is a boolean vector that determines if a given element should be processed with
the atomic RMW op. Elements with <code class="docutils literal notranslate"><span class="pre">mask[i]</span> <span class="pre">==</span> <span class="pre">0</span></code> are dropped (i.e., the atomic is not executed).
Similar to TT_AtomicRMWOp: Buffer atomic RMW ops load data at $ptr, do $rmw_op with $val, and store result to $ptr with
the specified memory semantics and scope. Atomic RMW ops return the pre-op value if used, otherwise the value is implicitly dropped.
Stride is the distance between the beginning of contiguous memory chunks. When performing a RMW, the <code class="docutils literal notranslate"><span class="pre">stride</span></code> is
the address difference between the first elements of each row in bytes. Compiler tries to obtain the <code class="docutils literal notranslate"><span class="pre">stride</span></code>
when it converts to the buffer ops because it is important for optimizing the cache memory access.</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">AttrSizedOperandSegments</span></code>, <code class="docutils literal notranslate"><span class="pre">SameLoadStoreOperandsAndResultEncoding</span></code></p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">BufferOpInterface</span></code></p>
<section id="id24">
<h3>Attributes:<a class="headerlink" href="#id24" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>atomic_rmw_op</code></td><td>::mlir::triton::RMWOpAttr</td><td>allowed 32-bit signless integer cases: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10</td></tr>
<tr><td><code>sem</code></td><td>::mlir::triton::MemSemanticAttr</td><td>allowed 32-bit signless integer cases: 1, 2, 3, 4</td></tr>
<tr><td><code>scope</code></td><td>::mlir::triton::MemSyncScopeAttr</td><td>allowed 32-bit signless integer cases: 1, 2, 3</td></tr>
</table>
</section>
<section id="id25">
<h3>Operands:<a class="headerlink" href="#id25" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">ptr</span></code></p></td>
<td><p>ptr</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">offsets</span></code></p></td>
<td><p>tensor of 32-bit signless integer values</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">value</span></code></p></td>
<td><p>ranked tensor of floating-point or integer or ptr values</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">stride</span></code></p></td>
<td><p>32-bit signless integer</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">mask</span></code></p></td>
<td><p>ranked tensor of 1-bit signless integer values</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id26">
<h3>Results:<a class="headerlink" href="#id26" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Result</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">result</span></code></p></td>
<td><p>ranked tensor of floating-point or integer or ptr values</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-buffer-load-triton-amdgpu-bufferloadop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.buffer_load</span></code> (triton::amdgpu::BufferLoadOp)<a class="headerlink" href="#amdg-buffer-load-triton-amdgpu-bufferloadop" title="Link to this heading">¶</a></h2>
<p><em>Load from a scalar base pointer and a tensor offset</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.buffer_load` $ptr `[` $offsets `]` (`,` $mask^)? (`,` $other^)?
              oilist(`cacheModifier` `=` $cache)
              (`stride` `=` $stride^)?
              attr-dict `:` type($result)
</pre></div>
</div>
<p>AMD Buffer load operation. Buffer store is similar to
a normal store but it accesses global memory via a scalar base pointer
and a tensor of offsets instead of a tensor of pointers. The other fields
are similar to a normal load, i.e., the <code class="docutils literal notranslate"><span class="pre">mask</span></code> is a boolean vector that
determines if a given element should be read from memory, and <code class="docutils literal notranslate"><span class="pre">other</span></code> is the
element that should be returned on lane <code class="docutils literal notranslate"><span class="pre">i</span></code> when <code class="docutils literal notranslate"><span class="pre">mask[i]</span> <span class="pre">==</span> <span class="pre">0</span></code>.
Stride is the distance between the beginning of contiguous memory chunks.
When performing a load of a block, the <code class="docutils literal notranslate"><span class="pre">stride</span></code> is the address difference between
the first elements of each row in bytes. Compiler tries to obtain the <code class="docutils literal notranslate"><span class="pre">stride</span></code>
when it converts to the buffer ops because it is important for optimizing
the cache memory access.
Contiguity is the maximum number of elements that can be loaded in a single vector
with the given layout and mask.
This allows to use buffer_load even if the alignment cannot be proven based on IR.</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">AttrSizedOperandSegments</span></code>, <code class="docutils literal notranslate"><span class="pre">SameLoadStoreOperandsAndResultEncoding</span></code></p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">BufferOpInterface</span></code></p>
<section id="id27">
<h3>Attributes:<a class="headerlink" href="#id27" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>cache</code></td><td>::mlir::triton::CacheModifierAttr</td><td>allowed 32-bit signless integer cases: 1, 2, 3, 4, 5, 6, 7</td></tr>
<tr><td><code>contiguity</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
</table>
</section>
<section id="id28">
<h3>Operands:<a class="headerlink" href="#id28" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">ptr</span></code></p></td>
<td><p>ptr</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">offsets</span></code></p></td>
<td><p>tensor of 32-bit signless integer values</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">stride</span></code></p></td>
<td><p>32-bit signless integer</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">mask</span></code></p></td>
<td><p>ranked tensor of 1-bit signless integer values</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">other</span></code></p></td>
<td><p>ranked tensor of floating-point or integer or ptr values</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id29">
<h3>Results:<a class="headerlink" href="#id29" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Result</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">result</span></code></p></td>
<td><p>ranked tensor of floating-point or integer or ptr values</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-buffer-load-to-local-triton-amdgpu-bufferloadtolocalop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.buffer_load_to_local</span></code> (triton::amdgpu::BufferLoadToLocalOp)<a class="headerlink" href="#amdg-buffer-load-to-local-triton-amdgpu-bufferloadtolocalop" title="Link to this heading">¶</a></h2>
<p><em>Load from a scalar base pointer and a tensor offset to shared memory</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.buffer_load_to_local` $ptr `[` $offsets `]` (`mask` `=` $mask^)? (`other` `=` $other^)? (`stride` `=` $stride^)?
              oilist(`cacheModifier` `=` $cache) `into` $dest
              attr-dict `:` type($ptr) `[` type($offsets) `]` type($other) `-&gt;` type($dest)
</pre></div>
</div>
<p>AMD Buffer load operation. Similar to amdg.buffer_load op but directly wirtes to shared memory instead of into registers.
Contiguity is the maximum number of elements that can be loaded in a single vector with the given layout and mask.
This allows to use buffer_load_to_local even if the alignment cannot be proven based on IR.</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">AttrSizedOperandSegments</span></code></p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">BufferOpInterface</span></code>, <code class="docutils literal notranslate"><span class="pre">InferTypeOpInterface</span></code></p>
<section id="id30">
<h3>Attributes:<a class="headerlink" href="#id30" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>cache</code></td><td>::mlir::triton::CacheModifierAttr</td><td>allowed 32-bit signless integer cases: 1, 2, 3, 4, 5, 6, 7</td></tr>
<tr><td><code>contiguity</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
</table>
</section>
<section id="id31">
<h3>Operands:<a class="headerlink" href="#id31" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">dest</span></code></p></td>
<td><p>memory descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::gpu::MemDescType</span></code>) in Triton IR type system</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">ptr</span></code></p></td>
<td><p>ptr</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">offsets</span></code></p></td>
<td><p>tensor of 32-bit signless integer values</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">mask</span></code></p></td>
<td><p>ranked tensor of 1-bit signless integer values</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">other</span></code></p></td>
<td><p>ranked tensor of floating-point or integer or ptr values</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">stride</span></code></p></td>
<td><p>32-bit signless integer</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id32">
<h3>Results:<a class="headerlink" href="#id32" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Result</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">token</span></code></p></td>
<td><p>async token type</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-buffer-store-triton-amdgpu-bufferstoreop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.buffer_store</span></code> (triton::amdgpu::BufferStoreOp)<a class="headerlink" href="#amdg-buffer-store-triton-amdgpu-bufferstoreop" title="Link to this heading">¶</a></h2>
<p><em>Store into scalar base pointer and a tensor offset</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.buffer_store` $value `,` $ptr `[` $offsets `]` (`,` $mask^)?
              oilist(`cacheModifier` `=` $cache)
              (`stride` `=` $stride^)?
              attr-dict `:` type($value)
</pre></div>
</div>
<p>AMD Buffer store operation. Buffer store is similar to
normal store but it accesses global memory via a scalar base pointer
and a tensor of offsets instead of a tensor of pointers. The other fields
are similar to a normal store , i.e., the <code class="docutils literal notranslate"><span class="pre">mask</span></code> is a boolean vector that
determines if a given element should be written to memory, and <code class="docutils literal notranslate"><span class="pre">value</span></code> is the
tensor of elements that should be written on lane <code class="docutils literal notranslate"><span class="pre">i</span></code> when <code class="docutils literal notranslate"><span class="pre">mask[i]</span> <span class="pre">==</span> <span class="pre">1</span></code>.
Stride is the distance between the beginning of contiguous memory chunks.
When performing a block store, the <code class="docutils literal notranslate"><span class="pre">stride</span></code> is the address difference between
the first elements of each row in bytes. Compiler tries to obtain the <code class="docutils literal notranslate"><span class="pre">stride</span></code>
when it converts to the buffer ops because it is important for optimizing
the cache memory access.
Contiguity is the maximum number of elements that can be loaded in a single vector
with the given layout and mask.
This allows to use buffer_store even if the alignment cannot be proven based on IR.</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">AttrSizedOperandSegments</span></code>, <code class="docutils literal notranslate"><span class="pre">SameLoadStoreOperandsEncoding</span></code></p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">BufferOpInterface</span></code></p>
<section id="id33">
<h3>Attributes:<a class="headerlink" href="#id33" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>cache</code></td><td>::mlir::triton::CacheModifierAttr</td><td>allowed 32-bit signless integer cases: 1, 2, 3, 4, 5, 6, 7</td></tr>
<tr><td><code>contiguity</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
</table>
</section>
<section id="id34">
<h3>Operands:<a class="headerlink" href="#id34" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">value</span></code></p></td>
<td><p>ranked tensor of floating-point or integer or ptr values</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">ptr</span></code></p></td>
<td><p>ptr</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">offsets</span></code></p></td>
<td><p>tensor of 32-bit signless integer values</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">stride</span></code></p></td>
<td><p>32-bit signless integer</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">mask</span></code></p></td>
<td><p>ranked tensor of 1-bit signless integer values</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-cluster-barrier-arrive-triton-amdgpu-clusterbarrierarriveop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.cluster_barrier_arrive</span></code> (triton::amdgpu::ClusterBarrierArriveOp)<a class="headerlink" href="#amdg-cluster-barrier-arrive-triton-amdgpu-clusterbarrierarriveop" title="Link to this heading">¶</a></h2>
<p><em>Arrive at a cluster barrier</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.cluster_barrier_arrive` attr-dict
</pre></div>
</div>
<p>Signals that the cluster has arrived at a barrier, used to synchronizing CTAs within a cluster.</p>
<p>See ClusterBarrierWaitOp for how to wait on the arrived cluster barrier.</p>
</section>
<section id="amdg-cluster-barrier-wait-triton-amdgpu-clusterbarrierwaitop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.cluster_barrier_wait</span></code> (triton::amdgpu::ClusterBarrierWaitOp)<a class="headerlink" href="#amdg-cluster-barrier-wait-triton-amdgpu-clusterbarrierwaitop" title="Link to this heading">¶</a></h2>
<p><em>Wait on a cluster barrier</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.cluster_barrier_wait` attr-dict
</pre></div>
</div>
<p>Waits for all CTAs of the same cluster to have arrived at a cluster barrier.
Arrive and wait operations must come in pairs. Waiting before arriving or arriving
more than once without a corresponding wait will result in undefined behavior.</p>
</section>
<section id="amdg-concat-triton-amdgpu-concatop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.concat</span></code> (triton::amdgpu::ConcatOp)<a class="headerlink" href="#amdg-concat-triton-amdgpu-concatop" title="Link to this heading">¶</a></h2>
<p><em>Concat operation</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.concat` $sources attr-dict `:` type($sources) `-&gt;` type($result)
</pre></div>
</div>
<p>The “concat” operation combines a list of source n-dimensional tensors into a single larger destination tensor.</p>
<p>All source tensors must have the same shape, element type, and encoding.
The concatenation dimension is inferred from the source and destination shapes provided by the user.
For example, two tensors of shape 64x128 can produce a destination shape of 128x128,
indicating concatenation along dimension 0; or 64x256, indicating concatenation along dimension 1.</p>
<p>Generally, source tensors passed as op arguments can be arranged into the resulting shape in multiple ways.
For example, given four tensors of shape 64x64:
concat s0&lt;64x64&gt;, s1&lt;64x64&gt;, s2&lt;64x64&gt;, s3&lt;64x64&gt; -&gt; &lt;128x128&gt;</p>
<p>They can be laid out in different configurations within the result tensor:</p>
<ol class="arabic simple">
<li><p>s0 s1     2) s0 s2
s2 s3        s1 s3</p></li>
</ol>
<p>From a logical tensor perspective, the source tensors are treated as elements of a tensor of tensors.
In other words, the 1-D array of input tensors is conceptually reshaped into an n-D grid.
The semantics of this op assume a row-major order (or its n-D generalization),
meaning the fastest-varying dimension is filled first, and the slowest-varying dimension is filled last.
In the example above, this corresponds to layout 1).</p>
<p>The source and destination tensors must have identical linear layouts at the CTA tile level.
That is, all base vectors for input dimensions must match, except for the register input dimension.
The register basis must align on the subset that defines the logical tensor shape of a single CTA tile.</p>
<p>This ensures that the concatenation is a no-op, meaning no data rearrangement among threads is required
to assemble the destination tensor with the given shape and layout.
However, the order of CTA tiles within the layout does not need to match between source and destination layouts.
It is the responsibility of the op’s lowering logic to handle this correctly.</p>
<p>This op is designed to work on logical tensors directly, avoiding the need for complex layout reinterpretation or reshaping.
For example, the <code class="docutils literal notranslate"><span class="pre">tt.join</span></code> operation only supports concatenation along the innermost dimension,
and requires that the resulting innermost dimension provide 2 elements per thread, distributed across registers.
In contrast, this <code class="docutils literal notranslate"><span class="pre">concat</span></code> op imposes no constraints on the concatenation dimension or the size of dimensions.</p>
<ul class="simple">
<li><p>sources: a list of the input tensors.</p></li>
</ul>
<p>Example 1:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>#blocked = #ttg.blocked&lt;{sizePerThread = [1, 8],
    threadsPerWarp = [8, 8], warpsPerCTA = [4, 1], order = [1, 0]}&gt;
%0 = amdg.concat %arg0, %arg1: tensor&lt;32x64xf32, #blocked&gt;,tensor&lt;32x64xf32, #blocked&gt;,
  -&gt; tensor&lt;64x64xf32, #blocked&gt;
</pre></div>
</div>
<p>Example 2:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>#src_layout = #ttg.linear&lt;{register=[[0, 1], [0, 2], [0, 8], [0, 16], [0, 64], [64, 0]], lane=[[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 4]], warp=[[0, 32], [32, 0]], block=[]}&gt;
#dst_layout = #ttg.linear&lt;{register=[[0, 1], [0, 2], [0, 8], [0, 16], [0, 64], [0, 128], [64, 0], [128, 0]], lane=[[1, 0], [2, 0], [4, 0], [8, 0], [16, 0], [0, 4]], warp=[[0, 32], [32, 0]], block=[]}&gt;
%0 = amdg.concat %arg0, %arg1, %arg2, %arg3 : tensor&lt;128x128xf16, #src_layout&gt;, tensor&lt;128x128xf16, #src_layout&gt;, tensor&lt;128x128xf16, #src_layout&gt;,
                                                tensor&lt;128x128xf16, #src_layout&gt; -&gt; tensor&lt;256x256xf16, #dst_layout&gt;
</pre></div>
</div>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">AlwaysSpeculatableImplTrait</span></code></p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">ConditionallySpeculatable</span></code>, <code class="docutils literal notranslate"><span class="pre">NoMemoryEffect</span> <span class="pre">(MemoryEffectOpInterface)</span></code></p>
<p>Effects: <code class="docutils literal notranslate"><span class="pre">MemoryEffects::Effect{}</span></code></p>
<section id="id35">
<h3>Operands:<a class="headerlink" href="#id35" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">sources</span></code></p></td>
<td><p>variadic of ranked tensor of floating-point or integer or ptr values</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id36">
<h3>Results:<a class="headerlink" href="#id36" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Result</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">result</span></code></p></td>
<td><p>ranked tensor of any type values</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-cond-barrier-triton-amdgpu-condbarrierop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.cond_barrier</span></code> (triton::amdgpu::CondBarrierOp)<a class="headerlink" href="#amdg-cond-barrier-triton-amdgpu-condbarrierop" title="Link to this heading">¶</a></h2>
<p><em>Conditionally set barriers to synchronize partial threads in a block</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.cond_barrier` $pred attr-dict
</pre></div>
</div>
<p>condBarrierOp sets barrier instruction only when the given argument is true.
This provides a way to synchronize partial threads in a block, deliberately
diverges the execution sequences. However, user should guarantee all threads
converge at the end by calling condBarrierOp(true) with the remaining threads.
Conceptually, this is similar to having an execution barrier inside an if statement.
This op allows us to avoid blocking the whole block when suitable to help scheduling.
NB. This doesn’t set any memory fence.</p>
<section id="id37">
<h3>Operands:<a class="headerlink" href="#id37" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">pred</span></code></p></td>
<td><p>1-bit signless integer</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-extract-slice-triton-amdgpu-extractsliceop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.extract_slice</span></code> (triton::amdgpu::ExtractSliceOp)<a class="headerlink" href="#amdg-extract-slice-triton-amdgpu-extractsliceop" title="Link to this heading">¶</a></h2>
<p><em>Extract slice operation</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.extract_slice` $source $static_offsets attr-dict `:` type($source) `to` type($result)
</pre></div>
</div>
<p>The “extract_slice” operation enables extracting a slice of a tensor in
registers.</p>
<p>The “extract_slice” operation supports the following arguments:</p>
<ul class="simple">
<li><p>source: the base tensor on which to create a view tensor</p></li>
<li><p>offsets: offsets into the base tensor at which to create the view</p></li>
</ul>
<p>In distributed layouts, tensors are divided into CTA tiles.
A CTA tile represents the smallest contiguous portion of a tensor that is
distributed across all threads and warps within a workgroup.
The ExtractSlice operation extracts a portion of the tensor that is a
multiple of CTA tiles.</p>
<p>The source and destination must have matching linear layouts at the CTA
tile level. This ensures that the extract_slice is a no-op, meaning no data
rearrangement between threads is required to extract the destination tensor
with the given shape and layout.</p>
<p>+——-+——-+
|  W0   |  W1   |
|       |       |
|   +   |   +   |
|  W2   |  W3   |  &lt;– Single CTA tile (distributed across warps W0-W3)
|       |       |
|   +   |   +   |
|       |       |
+——-+——-+
|          Source Tensor                    Extracted Slice
|             .                           +————–+
|             .                           |  W0  |  W1   |
|             .                           |      |       |
|                                         |  +   |   +   |
|                                         |  W2  |  W3   |
|                                         |      |       |
|                                         |  +   |   +   |
|                                         |      |       |
|                                         +——-+——+
|                                         |  W0  |   W1  |
|                                         |      |       |
|                                         |  +   |   +   |
|                                         |  W2     W3   |
|                                         |      |       |
|                                         |  +   |   +   |
|                                         |      |       |
|                                         +————–+</p>
<p>This op is designed to work on logical tensors directly, avoiding the need
for complex layout reinterpretation or reshaping. For example, the tt.split
operation only supports splitting along the innermost dimension,
and requires that the resulting innermost dimension provide 2 elements per thread,
distributed across registers. In contrast, extract_slice op imposes no constraints
on the extraction dimension or the size of dimensions.</p>
<p>Example 1:</p>
<div class="highlight-mlir notranslate"><div class="highlight"><pre><span></span>#blocked = #ttg.blocked&lt;{sizePerThread = [1, 8],
    threadsPerWarp = [4, 16], warpsPerCTA = [4, 1], order = [0, 1]}&gt;
#blocked1 = #ttg.blocked&lt;{sizePerThread = [1, 8],
    threadsPerWarp = [16, 4], warpsPerCTA = [4, 1], order = [0, 1]}&gt;
%1 = ttg.convert_layout %0 : tensor&lt;128x128xf16, #blocked&gt;
    -&gt; tensor&lt;128x128xf16, #blocked1&gt;
// create a slice of base tensor %1 with static offsets
%2 = amdg.extract_slice %0 [0, 0] :
  tensor&lt;128x128xf16, #blocked1&gt; to tensor&lt;128x32xf16, #blocked1&gt;
</pre></div>
</div>
<p>Example 1 shows how “extract_slice” operation may be used. In this example a
new slice of 128x32 is created. “extract_slice” works on tensors
where the desired slice has the same layout on a CTA tile as the source tensor.
“%0” cannot be sliced directly as the resulting slice does not satisfy this condition.
Therefore it needs to be converted to a layout suitable for slicing.
“#blocked1” layout is appropriate for this as it keeps the
sizePerThread the same thus keeping coalescing properties the same.
In order to utilize all threads in a warp, “threadsPerWarp” is set to
[16,4] for this new layout. This layout conversion carried out before
using “extract_slice” ensures slicing still uses all threads efficiently. The
size of the slice is determined by the result type.</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">AlwaysSpeculatableImplTrait</span></code></p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">ConditionallySpeculatable</span></code>, <code class="docutils literal notranslate"><span class="pre">NoMemoryEffect</span> <span class="pre">(MemoryEffectOpInterface)</span></code></p>
<p>Effects: <code class="docutils literal notranslate"><span class="pre">MemoryEffects::Effect{}</span></code></p>
<section id="id38">
<h3>Attributes:<a class="headerlink" href="#id38" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>static_offsets</code></td><td>::mlir::DenseI64ArrayAttr</td><td>i64 dense array attribute</td></tr>
</table>
</section>
<section id="id39">
<h3>Operands:<a class="headerlink" href="#id39" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">source</span></code></p></td>
<td><p>ranked tensor of any type values</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id40">
<h3>Results:<a class="headerlink" href="#id40" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Result</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">result</span></code></p></td>
<td><p>ranked tensor of any type values</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-in-thread-transpose-triton-amdgpu-inthreadtransposeop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.in_thread_transpose</span></code> (triton::amdgpu::InThreadTransposeOp)<a class="headerlink" href="#amdg-in-thread-transpose-triton-amdgpu-inthreadtransposeop" title="Link to this heading">¶</a></h2>
<p><em>Perform transpose of register values belonging to each threads</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.in_thread_transpose` $src attr-dict `:` type($src) `-&gt;` type($result)
</pre></div>
</div>
<p>This operation performs a layout transpose over values in registers per thread.
Specifically, given the input layout’s blocked layout, it transposes the two last dimensions(rank-1 and rank-2)
along the register dimension of the underlying linear layout.</p>
<p>Conversion example:</p>
<ul class="simple">
<li><p>input layout: blocked layout with sizePerThread=[2, 2], order=[0, 1]. It’s linear layout register bases = [[1, 0], [2, 0], [0, 1], [0, 2]]</p></li>
<li><p>output layout: same thread and warp bases as in input, register bases = [[0, 1], [0, 2], [1, 0], [2, 0]]</p></li>
</ul>
<p>This operation enables efficient coalesced loading from HBM with following vectorized writing to shared memory
in cases when HBM and shared memory order differ and target AMD hardware does not natively support this transposition.
This is a specific variant of ttg.convert_layout and will be converted to ttg.convert_layout when lowering to llvm.
We do not want this conversion to be optimized out, because we need to explicitly materialize instructions
to transpose within each thread after loading from HBM and before writing to shared memory.</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">AlwaysSpeculatableImplTrait</span></code></p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">ConditionallySpeculatable</span></code>, <code class="docutils literal notranslate"><span class="pre">NoMemoryEffect</span> <span class="pre">(MemoryEffectOpInterface)</span></code></p>
<p>Effects: <code class="docutils literal notranslate"><span class="pre">MemoryEffects::Effect{}</span></code></p>
<section id="id41">
<h3>Operands:<a class="headerlink" href="#id41" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">src</span></code></p></td>
<td><p>ranked tensor of floating-point or integer or ptr values</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id42">
<h3>Results:<a class="headerlink" href="#id42" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Result</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">result</span></code></p></td>
<td><p>ranked tensor of floating-point or integer or ptr values</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-init-barrier-triton-amdgpu-initbarrierop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.init_barrier</span></code> (triton::amdgpu::InitBarrierOp)<a class="headerlink" href="#amdg-init-barrier-triton-amdgpu-initbarrierop" title="Link to this heading">¶</a></h2>
<p><em>Initialize a barrier in the given shared memory allocation.</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.init_barrier` $alloc `,` $count attr-dict `:` qualified(type($alloc))
</pre></div>
</div>
<p>Initializes a shared memory allocation with mbarrier information.
<code class="docutils literal notranslate"><span class="pre">alloc</span></code> is a descriptor to the shared memory allocation. <code class="docutils literal notranslate"><span class="pre">count</span></code> is the
number of arrives expected by the barrier.</p>
<section id="id43">
<h3>Attributes:<a class="headerlink" href="#id43" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>count</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
</table>
</section>
<section id="id44">
<h3>Operands:<a class="headerlink" href="#id44" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">alloc</span></code></p></td>
<td><p>memory descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::gpu::MemDescType</span></code>) in Triton IR type system</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-instruction-sched-hint-triton-amdgpu-instructionschedhint">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.instruction_sched_hint</span></code> (triton::amdgpu::InstructionSchedHint)<a class="headerlink" href="#amdg-instruction-sched-hint-triton-amdgpu-instructionschedhint" title="Link to this heading">¶</a></h2>
<p><em>A placeholder op for instruction scheduling hints within a basic block</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.instruction_sched_hint` attr-dict
</pre></div>
</div>
<p>A placeholder op for instruction scheduling hints applied to instructions within
a basic block where the placeholder op is located. This op is primarily intended
to be used to adjust instruction scheduling inside the resulting main loop
of a <code class="docutils literal notranslate"><span class="pre">tt.dot</span></code> operation. It’s easier to identify dot ops at a high level and, thus,
to mark intended scheduling regions. The hint ops are eventually lowered
into LLVM AMDGPU instruction scheduling primitives, which are meant to control
how different kinds of instructions (valu/mfma, global/shared memory, etc.) should
interleave for better instruction level parallelism.</p>
<section id="id45">
<h3>Attributes:<a class="headerlink" href="#id45" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>variant</code></td><td>::mlir::triton::amdgpu::SchedHintAttr</td><td>Instruction Scheduling Hints for AMD GPUs</td></tr>
</table>
</section>
</section>
<section id="amdg-local-load-packed-tranposed-triton-amdgpu-localloadpackedtransposedop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.local_load_packed_tranposed</span></code> (triton::amdgpu::LocalLoadPackedTransposedOp)<a class="headerlink" href="#amdg-local-load-packed-tranposed-triton-amdgpu-localloadpackedtransposedop" title="Link to this heading">¶</a></h2>
<p><em>Load a transposed packed tensor from shared memory into a distributed tensor</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.local_load_packed_tranposed` $src (`token` $token^)? attr-dict `:` qualified(type($src)) `-&gt;` type($result)
</pre></div>
</div>
<p>Requires a M/N packed and M/N contiguous tensor in shared memory and will yield a K packed K contiguous tensor in registers.
The packing change will change the shape of the tensor by doubling the M/N dimension and halving the K dimension.
For example if A is 16x64 in shared memory, the result of this operation will be 32x32.</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">LocalLoadTrait</span></code></p>
<section id="id46">
<h3>Operands:<a class="headerlink" href="#id46" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">src</span></code></p></td>
<td><p>memory descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::gpu::MemDescType</span></code>) in Triton IR type system</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">token</span></code></p></td>
<td><p>async token type</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id47">
<h3>Results:<a class="headerlink" href="#id47" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Result</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">result</span></code></p></td>
<td><p>ranked tensor of floating-point or integer or ptr values</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-masked-load-triton-amdgpu-maskedloadop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.masked_load</span></code> (triton::amdgpu::MaskedLoadOp)<a class="headerlink" href="#amdg-masked-load-triton-amdgpu-maskedloadop" title="Link to this heading">¶</a></h2>
<p><em>Masked load operation</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.masked_load` $ptr `,` $mask `,` $falseVal (`,` $multicastMask^)?
              oilist(`cacheModifier` `=` $cache)
              (`forceNoAlias` $forceNoAlias^)?
              attr-dict `:` functional-type(operands, results)
</pre></div>
</div>
<p>Load operation with masking and multicast support. If the mask is true, loads from the given pointer. Works with LLVM types as a utility op for making LLVM conversion easier.
On architectures supporting multicast, the <code class="docutils literal notranslate"><span class="pre">multicastMask</span></code>specifies which CTAs in the cluster request the same data. This allows the hardware to efficiently broadcast the
data to multiple CTAs in the cluster.</p>
<section id="id48">
<h3>Attributes:<a class="headerlink" href="#id48" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>cache</code></td><td>::mlir::triton::CacheModifierAttr</td><td>allowed 32-bit signless integer cases: 1, 2, 3, 4, 5, 6, 7</td></tr>
<tr><td><code>forceNoAlias</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr>
</table>
</section>
<section id="id49">
<h3>Operands:<a class="headerlink" href="#id49" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">ptr</span></code></p></td>
<td><p>LLVM pointer type</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">mask</span></code></p></td>
<td><p>1-bit signless integer</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">falseVal</span></code></p></td>
<td><p>LLVM dialect-compatible type</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">multicastMask</span></code></p></td>
<td><p>16-bit signless integer</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id50">
<h3>Results:<a class="headerlink" href="#id50" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Result</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">result</span></code></p></td>
<td><p>LLVM dialect-compatible type</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-masked-store-triton-amdgpu-maskedstoreop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.masked_store</span></code> (triton::amdgpu::MaskedStoreOp)<a class="headerlink" href="#amdg-masked-store-triton-amdgpu-maskedstoreop" title="Link to this heading">¶</a></h2>
<p><em>Masked Store operation</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.masked_store` $ptr `,` $value `,` $mask
              oilist(`cacheModifier` `=` $cache)
              (`forceNoAlias` $forceNoAlias^)?
              attr-dict `:` type(operands)
</pre></div>
</div>
<p>Store operation with masking support. If the mask is true, Store from the given pointer. Works with LLVM types as a utility op for making LLVM conversion easier.</p>
<section id="id51">
<h3>Attributes:<a class="headerlink" href="#id51" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>cache</code></td><td>::mlir::triton::CacheModifierAttr</td><td>allowed 32-bit signless integer cases: 1, 2, 3, 4, 5, 6, 7</td></tr>
<tr><td><code>forceNoAlias</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr>
</table>
</section>
<section id="id52">
<h3>Operands:<a class="headerlink" href="#id52" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">ptr</span></code></p></td>
<td><p>LLVM pointer type</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">value</span></code></p></td>
<td><p>LLVM dialect-compatible type</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">mask</span></code></p></td>
<td><p>1-bit signless integer</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-memory-counter-wait-triton-amdgpu-memorycounterwaitop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.memory_counter_wait</span></code> (triton::amdgpu::MemoryCounterWaitOp)<a class="headerlink" href="#amdg-memory-counter-wait-triton-amdgpu-memorycounterwaitop" title="Link to this heading">¶</a></h2>
<p><em>Wait for specified hardware counters</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.memory_counter_wait` oilist( `load` `(` $load `)` | `store` `(` $store `)` | `ds` `(` $ds `)` ) attr-dict
</pre></div>
</div>
<p>Wait for the specified counters to be less-than or equal-to the provided
values before continuing.</p>
<p>Counters can lower to different instructions on different architectires,
including clamping to the some HW supported max value or combining multiple
counters into one.</p>
<section id="id53">
<h3>Attributes:<a class="headerlink" href="#id53" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>load</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
<tr><td><code>store</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
<tr><td><code>ds</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
</table>
</section>
</section>
<section id="amdg-scaled-upcast-fp4-triton-amdgpu-scaledupcastfp4op">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.scaled_upcast_fp4</span></code> (triton::amdgpu::ScaledUpcastFp4Op)<a class="headerlink" href="#amdg-scaled-upcast-fp4-triton-amdgpu-scaledupcastfp4op" title="Link to this heading">¶</a></h2>
<p><em>Upcast fp4 and then multiply scale</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.scaled_upcast_fp4` $input `scale` $scale attr-dict
              `:` type($input) `,` type($scale) `-&gt;` type($output)
</pre></div>
</div>
<p>Upcast fp4 (e2m1) values packed as i8 values and multiply with the given
E8M0 scale encoded as BF16. This maps to <code class="docutils literal notranslate"><span class="pre">v_cvt_scalef32_*</span></code> intrinsics
on the AMD CDNA4 architecture.</p>
<p>The lower 4 bits of the i8s represent the first fp4 element, and the upper
4 bits the second fp4 element.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">axis</span></code> attribute specifies the axis along which the fp4 elements are
packed.</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">AlwaysSpeculatableImplTrait</span></code></p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">ConditionallySpeculatable</span></code>, <code class="docutils literal notranslate"><span class="pre">NoMemoryEffect</span> <span class="pre">(MemoryEffectOpInterface)</span></code>, <code class="docutils literal notranslate"><span class="pre">UpcastFpOpInterface</span></code></p>
<p>Effects: <code class="docutils literal notranslate"><span class="pre">MemoryEffects::Effect{}</span></code></p>
<section id="id54">
<h3>Attributes:<a class="headerlink" href="#id54" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>axis</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
</table>
</section>
<section id="id55">
<h3>Operands:<a class="headerlink" href="#id55" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">input</span></code></p></td>
<td><p>ranked tensor of 8-bit signless integer values</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">scale</span></code></p></td>
<td><p>ranked tensor of bfloat16 type or 8-bit signless integer values</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id56">
<h3>Results:<a class="headerlink" href="#id56" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Result</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">output</span></code></p></td>
<td><p>ranked tensor of 16-bit float or bfloat16 type or 32-bit float values</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-scaled-upcast-fp8-triton-amdgpu-scaledupcastfp8op">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.scaled_upcast_fp8</span></code> (triton::amdgpu::ScaledUpcastFp8Op)<a class="headerlink" href="#amdg-scaled-upcast-fp8-triton-amdgpu-scaledupcastfp8op" title="Link to this heading">¶</a></h2>
<p><em>Upcast Fp8 and then multiply scale</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.scaled_upcast_fp8` $input `scale` $scale attr-dict
              `:` type($input) `,` type($scale) `-&gt;` type($output)
</pre></div>
</div>
<p>Upcast fp8 (e4m3/e5m2) values and multiply with the given E8M0 scale
encoded as BF16. This maps to <code class="docutils literal notranslate"><span class="pre">v_cvt_scalef32_*</span></code> intrinsics
on the AMD CDNA4 architecture.</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">AlwaysSpeculatableImplTrait</span></code>, <code class="docutils literal notranslate"><span class="pre">Elementwise</span></code>, <code class="docutils literal notranslate"><span class="pre">SameOperandsAndResultEncoding</span></code>, <code class="docutils literal notranslate"><span class="pre">SameOperandsAndResultShape</span></code></p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">ConditionallySpeculatable</span></code>, <code class="docutils literal notranslate"><span class="pre">NoMemoryEffect</span> <span class="pre">(MemoryEffectOpInterface)</span></code>, <code class="docutils literal notranslate"><span class="pre">UpcastFpOpInterface</span></code></p>
<p>Effects: <code class="docutils literal notranslate"><span class="pre">MemoryEffects::Effect{}</span></code></p>
<section id="id57">
<h3>Operands:<a class="headerlink" href="#id57" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">input</span></code></p></td>
<td><p>ranked tensor of f8E4M3FN type or f8E5M2 type values</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">scale</span></code></p></td>
<td><p>ranked tensor of bfloat16 type or 8-bit signless integer values</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id58">
<h3>Results:<a class="headerlink" href="#id58" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Result</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">output</span></code></p></td>
<td><p>ranked tensor of 16-bit float or bfloat16 type or 32-bit float values</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-tdm-prefetch-triton-amdgpu-tdmprefetchop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.tdm_prefetch</span></code> (triton::amdgpu::TDMPrefetchOp)<a class="headerlink" href="#amdg-tdm-prefetch-triton-amdgpu-tdmprefetchop" title="Link to this heading">¶</a></h2>
<p><em>Prefetch data based on a TDM descriptor from global memory to L2.</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.tdm_prefetch` $desc `[` $indices `]` `,` $pred `,` `speculative` `=` $speculative
              (`returnOffsets` $returnOffsets^)?
              attr-dict `:` qualified(type($desc))
              (`-&gt;` type($maybeOffsets)^)?
</pre></div>
</div>
<p>This operation prefetches data from global memory to L2. It is analogous to the AsyncTDMCopyGlobalToLocalOp,
but it does not copy the data to local memory and instead only prefetches the data into the L2 cache.
Speculative prefetches can generate more efficient assembly because they do not require out of bounds checks.
However, they are dropped by the hardware in case the virtual address translation is not already cached at CU level.</p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">InferTypeOpInterface</span></code>, <code class="docutils literal notranslate"><span class="pre">MemoryEffectOpInterface</span> <span class="pre">(MemoryEffectOpInterface)</span></code></p>
<p>Effects: <code class="docutils literal notranslate"><span class="pre">MemoryEffects::Effect{MemoryEffects::Write</span> <span class="pre">on</span> <span class="pre">::mlir::triton::amd::L2Cache}</span></code></p>
<section id="id59">
<h3>Attributes:<a class="headerlink" href="#id59" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>speculative</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr>
<tr><td><code>returnOffsets</code></td><td>::mlir::UnitAttr</td><td>unit attribute</td></tr>
</table>
</section>
<section id="id60">
<h3>Operands:<a class="headerlink" href="#id60" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">desc</span></code></p></td>
<td><p>Tensor descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::TensorDescType</span></code>) in Triton IR type system</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">indices</span></code></p></td>
<td><p>variadic of 32-bit signless integer</p></td>
</tr>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">pred</span></code></p></td>
<td><p>1-bit signless integer</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id61">
<h3>Results:<a class="headerlink" href="#id61" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Result</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">maybeOffsets</span></code></p></td>
<td><p>ranked tensor of floating-point or integer or ptr values</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-upcast-mxfp-triton-amdgpu-upcastmxfpop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.upcast_mxfp</span></code> (triton::amdgpu::UpcastMXFPOp)<a class="headerlink" href="#amdg-upcast-mxfp-triton-amdgpu-upcastmxfpop" title="Link to this heading">¶</a></h2>
<p><em>Convert an mxfp tensor to bf16/fp16</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.upcast_mxfp` $src `,` $scale  `fp_type` `=` $fp_type attr-dict `:` type($src) `,` type($scale) `-&gt;` type($result)
</pre></div>
</div>
<p>Compute the bf16 encoded in the given mxfp number as per
https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf</p>
<p>Traits: <code class="docutils literal notranslate"><span class="pre">AlwaysSpeculatableImplTrait</span></code></p>
<p>Interfaces: <code class="docutils literal notranslate"><span class="pre">ConditionallySpeculatable</span></code>, <code class="docutils literal notranslate"><span class="pre">NoMemoryEffect</span> <span class="pre">(MemoryEffectOpInterface)</span></code></p>
<p>Effects: <code class="docutils literal notranslate"><span class="pre">MemoryEffects::Effect{}</span></code></p>
<section id="id62">
<h3>Attributes:<a class="headerlink" href="#id62" title="Link to this heading">¶</a></h3>
<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>fp_type</code></td><td>::mlir::triton::ScaleDotElemTypeAttr</td><td>allowed 32-bit signless integer cases: 0, 1, 2, 3, 4, 5, 6</td></tr>
<tr><td><code>fastMath</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr>
</table>
</section>
<section id="id63">
<h3>Operands:<a class="headerlink" href="#id63" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">src</span></code></p></td>
<td><p>ranked tensor of floating-point or integer or ptr values</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">scale</span></code></p></td>
<td><p>ranked tensor of floating-point or integer or ptr values</p></td>
</tr>
</tbody>
</table>
</section>
<section id="id64">
<h3>Results:<a class="headerlink" href="#id64" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Result</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">result</span></code></p></td>
<td><p>ranked tensor of floating-point or integer or ptr values</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="amdg-wait-barrier-triton-amdgpu-waitbarrierop">
<h2><code class="docutils literal notranslate"><span class="pre">amdg.wait_barrier</span></code> (triton::amdgpu::WaitBarrierOp)<a class="headerlink" href="#amdg-wait-barrier-triton-amdgpu-waitbarrierop" title="Link to this heading">¶</a></h2>
<p><em>Wait until the mbarrier phase completes.</em></p>
<p>Syntax:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>operation ::= `amdg.wait_barrier` $alloc `,` $phase attr-dict `:` qualified(type($alloc))
</pre></div>
</div>
<p>Blocks the program progress until the mbarrier object in <code class="docutils literal notranslate"><span class="pre">alloc</span></code> completes
its current phase.</p>
<section id="id65">
<h3>Operands:<a class="headerlink" href="#id65" title="Link to this heading">¶</a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head text-center"><p>Operand</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">alloc</span></code></p></td>
<td><p>memory descriptor type (<code class="docutils literal notranslate"><span class="pre">::mlir::triton::gpu::MemDescType</span></code>) in Triton IR type system</p></td>
</tr>
<tr class="row-odd"><td class="text-center"><p><code class="docutils literal notranslate"><span class="pre">phase</span></code></p></td>
<td><p>32-bit signless integer</p></td>
</tr>
</tbody>
</table>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="TritonInstrumentOps.html" class="btn btn-neutral float-left" title="TritonInstrumentOps" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="TritonGPUOps.html" class="btn btn-neutral float-right" title="TritonGPUOps" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, Philippe Tillet.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>